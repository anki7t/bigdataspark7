
Big data is defined by four v
velocity
veracity
variety
volume

monolithic system is not scalable, distributed system is scalable.
monolithic-->adding more power to same machine like keeping box on top of another
distributed--->adding more resource machine in network like keeping box horizontal next to another box.
monolithic is called vertical scaling
distributed is called horizontal scaling.

two kind of things--1.Namenode 2.datanode
it has master slave architecture.
we can call it co-ordinator and executor nodes.

whenever a request comes it goes to namenode first , then namenode checks the metadata entry table for requested data.
name node maintains a table of metadata it has information about which data nodes contains which data.

default block size is 128mb.

just to understand take small example..if you have file of 300mb file. this will be divided in 128*3 three parts
first part will have 128mb,second part will have 128mb,third part will have 44mb.so it will have three data chunks that will be distributed across cluster of data nodes.
further based on replication factor this data will be kept with some copy common practice is keeping 3 copy said as data with 3 replication factor.

name node failure is handled by secondary name node. that keeps accepting info from primary name node as process of check pointing.

there are databases like hive, Casandra, Hbase hive is sql based others are no sql db(database).
Hive commonly widely used. it has its engine (either MR,Spark,Tej).

hive acts as query tool for data in  big data. you can have your data in hdfs and query with hive.
when you query data comes from hdfs and schema from hive metastore and it gives combining a table view of data.

there are several function in hive specially sql functions.
most popular one is partition and bucketing.

